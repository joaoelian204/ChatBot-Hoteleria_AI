#!/usr/bin/env python3
"""
üß™ SISTEMA DE TESTING UNIVERSAL PROFESIONAL PARA CHATBOT
=========================================================

Sistema de testing avanzado que eval√∫a todas las funciones del chatbot
con diferentes niveles de dificultad y casos edge complejos.

Caracter√≠sticas:
- Tests unitarios y de integraci√≥n
- Benchmarking de rendimiento
- Tests de estr√©s y robustez
- Validaci√≥n de respuestas
- M√©tricas de calidad
- Tests de casos extremos

Uso:
    python -m src.testing.test_suite
    python -m src.testing.test_suite --mode stress
    python -m src.testing.test_suite --difficulty hard
"""

import json
import sys
import time
import traceback
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Optional

import colorama
from colorama import Fore

# Configurar path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from ai.fallback_handler import (
        generate_fallback_response,
        get_amenities_info_from_documents,
        get_cheapest_room_info,
        get_contact_info_from_documents,
        get_hotel_name_from_documents,
        get_most_expensive_room_info,
        get_restaurant_info_from_documents,
        get_room_info_from_documents,
        get_time_based_greeting,
        normalize_text,
        read_document_safely,
    )
except ImportError as e:
    print(f"‚ùå Error al importar m√≥dulos: {e}")
    print("Aseg√∫rate de ejecutar desde el directorio ra√≠z del proyecto")
    sys.exit(1)

# Inicializar colorama
colorama.init(autoreset=True)


@dataclass
class TestResult:
    """Resultado de un test individual"""
    name: str
    passed: bool
    duration: float
    expected: Optional[str] = None
    actual: Optional[str] = None
    error: Optional[str] = None
    performance_score: Optional[float] = None


@dataclass
class TestSuiteResult:
    """Resultado completo de la suite de tests"""
    total_tests: int = 0
    passed: int = 0
    failed: int = 0
    skipped: int = 0
    total_duration: float = 0.0
    coverage_score: float = 0.0
    performance_score: float = 0.0
    results: List[TestResult] = None

    def __post_init__(self):
        if self.results is None:
            self.results = []


class ChatbotTestSuite:
    """Suite de testing profesional para el chatbot"""

    def __init__(self, difficulty: str = "medium", verbose: bool = True):
        self.difficulty = difficulty
        self.verbose = verbose
        self.test_results = TestSuiteResult()
        self.start_time = time.time()

        # Configuraci√≥n de dificultad
        self.difficulty_configs = {
            "easy": {
                "stress_iterations": 10,
                "concurrent_tests": 2,
                "timeout": 5.0,
                "edge_cases": False
            },
            "medium": {
                "stress_iterations": 50,
                "concurrent_tests": 5,
                "timeout": 3.0,
                "edge_cases": True
            },
            "hard": {
                "stress_iterations": 100,
                "concurrent_tests": 10,
                "timeout": 1.0,
                "edge_cases": True
            },
            "nightmare": {
                "stress_iterations": 500,
                "concurrent_tests": 20,
                "timeout": 0.5,
                "edge_cases": True
            }
        }

        self.config = self.difficulty_configs.get(difficulty, self.difficulty_configs["medium"])

        # Tests b√°sicos
        self.basic_tests = [
            ("Saludo b√°sico", "hola"),
            ("Saludo formal", "Buenos d√≠as"),
            ("Habitaci√≥n econ√≥mica", "cu√°l es la habitaci√≥n m√°s barata"),
            ("Habitaci√≥n lujosa", "habitaci√≥n m√°s cara"),
            ("Restaurantes", "informaci√≥n sobre restaurantes"),
            ("Men√∫s", "precios de los men√∫s"),
            ("Amenidades", "qu√© actividades tienen"),
            ("Contacto", "informaci√≥n de contacto"),
            ("Reservas", "c√≥mo hacer una reserva"),
            ("Ayuda", "ayuda")
        ]

        # Tests de dificultad media
        self.medium_tests = [
            ("Consulta con errores tipogr√°ficos", "abl me gustari saver de las avitasiones"),
            ("Consulta mezclada", "Hola, necesito saber precios de habitaciones y restaurantes"),
            ("Consulta en ingl√©s", "What are your room prices?"),
            ("Consulta con caracteres especiales", "¬øCu√°l es la habitaci√≥n m√°s econ√≥mica? üí∞üè†"),
            ("Consulta muy larga", "Me gustar√≠a obtener informaci√≥n detallada sobre todas las habitaciones disponibles en el hotel, incluyendo precios, servicios incluidos, amenidades, pol√≠ticas de cancelaci√≥n y disponibilidad para las pr√≥ximas fechas"),
            ("Consulta ambigua", "precio"),
            ("Consulta sin contexto", "¬øcu√°nto cuesta?"),
            ("M√∫ltiples preguntas", "¬øCu√°les son los precios de las habitaciones y qu√© restaurantes tienen?")
        ]

        # Tests extremos (hard/nightmare)
        self.extreme_tests = [
            ("Texto vac√≠o", ""),
            ("Solo espacios", "   "),
            ("Solo s√≠mbolos", "!@#$%^&*()"),
            ("Texto muy largo", "a" * 1000),
            ("Caracteres unicode", "üè®üçΩÔ∏èüèä‚Äç‚ôÇÔ∏èüí∞üåü"),
            ("HTML/Scripts", "<script>alert('test')</script>"),
            ("SQL injection", "'; DROP TABLE users; --"),
            ("Path traversal", "../../../etc/passwd"),
            ("N√∫meros aleatorios", "123456789"),
            ("Caracteres especiales", "√ß√±√°√©√≠√≥√∫√º"),
            ("Texto en otros idiomas", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –≥–¥–µ —Ä–µ—Å—Ç–æ—Ä–∞–Ω?"),
            ("JSON malformado", '{"test": incomplete'),
            ("XML malformado", "<xml><unclosed>"),
            ("URLs", "https://malicious-site.com/hack"),
            ("Comandos shell", "rm -rf /")
        ]

    def print_header(self):
        """Imprime el header del sistema de testing"""
        print(f"\n{Fore.CYAN}{'=' * 80}")
        print(f"{Fore.CYAN}üß™ SISTEMA DE TESTING UNIVERSAL - CHATBOT DE HOTELER√çA ü§ñ")
        print(f"{Fore.CYAN}{'=' * 80}")
        print(f"{Fore.YELLOW}üìä Dificultad: {self.difficulty.upper()}")
        print(f"{Fore.YELLOW}‚öôÔ∏è  Configuraci√≥n:")
        print(f"{Fore.WHITE}   - Tests de estr√©s: {self.config['stress_iterations']}")
        print(f"{Fore.WHITE}   - Tests concurrentes: {self.config['concurrent_tests']}")
        print(f"{Fore.WHITE}   - Timeout: {self.config['timeout']}s")
        print(f"{Fore.WHITE}   - Casos extremos: {'S√≠' if self.config['edge_cases'] else 'No'}")
        print(f"{Fore.CYAN}{'=' * 80}\n")

    def run_test(self, test_name: str, test_input: str, expected_keywords: List[str] = None) -> TestResult:
        """Ejecuta un test individual y mide el rendimiento"""
        start_time = time.time()

        try:
            # Ejecutar el test con timeout
            result = self._execute_with_timeout(
                lambda: generate_fallback_response(test_input),
                self.config['timeout']
            )

            duration = time.time() - start_time

            # Validar el resultado
            if result is None or not isinstance(result, str):
                return TestResult(
                    name=test_name,
                    passed=False,
                    duration=duration,
                    actual=str(result),
                    error="Respuesta inv√°lida o None"
                )

            # Verificar keywords esperadas
            passed = True
            if expected_keywords:
                result_lower = result.lower()
                for keyword in expected_keywords:
                    if keyword.lower() not in result_lower:
                        passed = False
                        break

            # Calcular score de rendimiento
            performance_score = min(100.0, (1.0 / max(duration, 0.001)) * 10)

            return TestResult(
                name=test_name,
                passed=passed,
                duration=duration,
                actual=result[:200] + "..." if len(result) > 200 else result,
                performance_score=performance_score
            )

        except Exception as e:
            duration = time.time() - start_time
            return TestResult(
                name=test_name,
                passed=False,
                duration=duration,
                error=str(e),
                performance_score=0.0
            )

    def _execute_with_timeout(self, func, timeout):
        """Ejecuta una funci√≥n con timeout"""
        import signal

        def timeout_handler(signum, frame):
            raise TimeoutError("Test excedi√≥ el tiempo l√≠mite")

        # Configurar timeout (solo en sistemas Unix)
        if hasattr(signal, 'SIGALRM'):
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(int(timeout))

        try:
            result = func()
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)  # Cancelar timeout
            return result
        except TimeoutError:
            raise
        except Exception as e:
            if hasattr(signal, 'SIGALRM'):
                signal.alarm(0)
            raise e

    def test_basic_functionality(self):
        """Tests b√°sicos de funcionalidad"""
        print(f"{Fore.GREEN}üìã EJECUTANDO TESTS B√ÅSICOS...")

        for test_name, test_input in self.basic_tests:
            result = self.run_test(test_name, test_input)
            self._add_result(result)

            if self.verbose:
                status = f"{Fore.GREEN}‚úÖ PASS" if result.passed else f"{Fore.RED}‚ùå FAIL"
                print(f"  {status} {test_name} ({result.duration:.3f}s)")
                if not result.passed and result.error:
                    print(f"    {Fore.RED}Error: {result.error}")

    def test_medium_difficulty(self):
        """Tests de dificultad media"""
        print(f"\n{Fore.YELLOW}üìä EJECUTANDO TESTS DE DIFICULTAD MEDIA...")

        for test_name, test_input in self.medium_tests:
            result = self.run_test(test_name, test_input)
            self._add_result(result)

            if self.verbose:
                status = f"{Fore.GREEN}‚úÖ PASS" if result.passed else f"{Fore.RED}‚ùå FAIL"
                print(f"  {status} {test_name} ({result.duration:.3f}s)")

    def test_extreme_cases(self):
        """Tests de casos extremos"""
        if not self.config['edge_cases']:
            return

        print(f"\n{Fore.RED}üî• EJECUTANDO TESTS EXTREMOS...")

        for test_name, test_input in self.extreme_tests:
            result = self.run_test(test_name, test_input)
            self._add_result(result)

            if self.verbose:
                status = f"{Fore.GREEN}‚úÖ PASS" if result.passed else f"{Fore.RED}‚ùå FAIL"
                print(f"  {status} {test_name} ({result.duration:.3f}s)")

    def test_performance_stress(self):
        """Tests de estr√©s y rendimiento"""
        print(f"\n{Fore.MAGENTA}‚ö° EJECUTANDO TESTS DE ESTR√âS...")

        stress_queries = [
            "hola",
            "habitaci√≥n m√°s barata",
            "restaurantes",
            "contacto"
        ]

        total_time = 0
        successful_requests = 0

        for i in range(self.config['stress_iterations']):
            query = stress_queries[i % len(stress_queries)]
            start_time = time.time()

            try:
                result = generate_fallback_response(query)
                duration = time.time() - start_time
                total_time += duration

                if result and isinstance(result, str) and len(result) > 0:
                    successful_requests += 1

            except Exception:
                duration = time.time() - start_time
                total_time += duration

            if self.verbose and i % 10 == 0:
                print(f"  Progreso: {i}/{self.config['stress_iterations']} ({(i / self.config['stress_iterations'] * 100):.1f}%)")

        avg_response_time = total_time / self.config['stress_iterations']
        success_rate = successful_requests / self.config['stress_iterations'] * 100

        # Crear resultado del test de estr√©s
        stress_result = TestResult(
            name="Test de Estr√©s",
            passed=success_rate >= 90 and avg_response_time <= 1.0,
            duration=total_time,
            performance_score=success_rate
        )

        self._add_result(stress_result)

        print(f"  {Fore.CYAN}üìà Tiempo promedio de respuesta: {avg_response_time:.3f}s")
        print(f"  {Fore.CYAN}üìä Tasa de √©xito: {success_rate:.1f}%")

    def test_concurrent_access(self):
        """Tests de acceso concurrente"""
        print(f"\n{Fore.BLUE}üîÑ EJECUTANDO TESTS CONCURRENTES...")

        def worker_task(worker_id):
            results = []
            queries = ["hola", "habitaciones", "restaurantes", "contacto"]

            for i in range(5):  # Cada worker hace 5 requests
                query = f"{queries[i % len(queries)]} worker-{worker_id}"
                start_time = time.time()

                try:
                    result = generate_fallback_response(query)
                    duration = time.time() - start_time

                    success = result and isinstance(result, str) and len(result) > 0
                    results.append((success, duration))

                except Exception:
                    results.append((False, time.time() - start_time))

            return results

        # Ejecutar workers concurrentes
        with ThreadPoolExecutor(max_workers=self.config['concurrent_tests']) as executor:
            futures = [executor.submit(worker_task, i) for i in range(self.config['concurrent_tests'])]
            all_results = []

            for future in futures:
                try:
                    worker_results = future.result(timeout=10)
                    all_results.extend(worker_results)
                except Exception as e:
                    print(f"  {Fore.RED}‚ùå Worker fall√≥: {e}")

        # Analizar resultados
        successful = sum(1 for success, _ in all_results if success)
        total = len(all_results)
        avg_time = sum(duration for _, duration in all_results) / total if total > 0 else 0

        concurrent_result = TestResult(
            name="Test Concurrente",
            passed=successful / total >= 0.9 if total > 0 else False,
            duration=avg_time,
            performance_score=successful / total * 100 if total > 0 else 0
        )

        self._add_result(concurrent_result)

        print(f"  {Fore.CYAN}üî¢ Requests exitosos: {successful}/{total}")
        print(f"  {Fore.CYAN}‚è±Ô∏è  Tiempo promedio: {avg_time:.3f}s")

    def test_document_integration(self):
        """Tests de integraci√≥n con documentos"""
        print(f"\n{Fore.CYAN}üìÑ EJECUTANDO TESTS DE INTEGRACI√ìN...")

        # Test de lectura de documentos
        docs_to_test = [
            "hotel_info.txt",
            "habitaciones_precios.txt",
            "restaurantes_menus.txt",
            "amenidades_actividades.txt"
        ]

        for doc in docs_to_test:
            start_time = time.time()
            try:
                content = read_document_safely(doc)
                duration = time.time() - start_time

                doc_result = TestResult(
                    name=f"Lectura {doc}",
                    passed=len(content) > 0,
                    duration=duration,
                    actual=f"Contenido: {len(content)} caracteres"
                )

            except Exception as e:
                duration = time.time() - start_time
                doc_result = TestResult(
                    name=f"Lectura {doc}",
                    passed=False,
                    duration=duration,
                    error=str(e)
                )

            self._add_result(doc_result)

            if self.verbose:
                status = f"{Fore.GREEN}‚úÖ PASS" if doc_result.passed else f"{Fore.RED}‚ùå FAIL"
                print(f"  {status} {doc_result.name} ({doc_result.duration:.3f}s)")

    def test_functions_individually(self):
        """Tests de funciones individuales"""
        print(f"\n{Fore.MAGENTA}üîß EJECUTANDO TESTS DE FUNCIONES INDIVIDUALES...")

        functions_to_test = [
            ("get_hotel_name_from_documents", get_hotel_name_from_documents, []),
            ("get_time_based_greeting", get_time_based_greeting, []),
            ("normalize_text", normalize_text, ["¬°Hola! ¬øC√≥mo est√°?"]),
            ("get_room_info_from_documents", get_room_info_from_documents, []),
            ("get_cheapest_room_info", get_cheapest_room_info, []),
            ("get_most_expensive_room_info", get_most_expensive_room_info, []),
            ("get_restaurant_info_from_documents", get_restaurant_info_from_documents, []),
            ("get_amenities_info_from_documents", get_amenities_info_from_documents, []),
            ("get_contact_info_from_documents", get_contact_info_from_documents, [])
        ]

        for func_name, func, args in functions_to_test:
            start_time = time.time()
            try:
                result = func(*args)
                duration = time.time() - start_time

                func_result = TestResult(
                    name=f"Funci√≥n {func_name}",
                    passed=result is not None,
                    duration=duration,
                    actual=str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
                )

            except Exception as e:
                duration = time.time() - start_time
                func_result = TestResult(
                    name=f"Funci√≥n {func_name}",
                    passed=False,
                    duration=duration,
                    error=str(e)
                )

            self._add_result(func_result)

            if self.verbose:
                status = f"{Fore.GREEN}‚úÖ PASS" if func_result.passed else f"{Fore.RED}‚ùå FAIL"
                print(f"  {status} {func_result.name} ({func_result.duration:.3f}s)")

    def _add_result(self, result: TestResult):
        """A√±ade un resultado a la suite"""
        self.test_results.results.append(result)
        self.test_results.total_tests += 1

        if result.passed:
            self.test_results.passed += 1
        else:
            self.test_results.failed += 1

    def generate_report(self):
        """Genera un reporte completo de los tests"""
        end_time = time.time()
        self.test_results.total_duration = end_time - self.start_time

        # Calcular m√©tricas
        pass_rate = (self.test_results.passed / self.test_results.total_tests * 100) if self.test_results.total_tests > 0 else 0
        avg_duration = sum(r.duration for r in self.test_results.results) / len(self.test_results.results) if self.test_results.results else 0
        avg_performance = sum(r.performance_score for r in self.test_results.results if r.performance_score) / len([r for r in self.test_results.results if r.performance_score]) if any(r.performance_score for r in self.test_results.results) else 0

        # Header del reporte
        print(f"\n{Fore.CYAN}{'=' * 80}")
        print(f"{Fore.CYAN}üìä REPORTE FINAL DE TESTING")
        print(f"{Fore.CYAN}{'=' * 80}")

        # Resumen general
        print(f"\n{Fore.YELLOW}üìà RESUMEN GENERAL:")
        print(f"{Fore.WHITE}   Total de tests: {self.test_results.total_tests}")
        print(f"{Fore.GREEN}   ‚úÖ Pasados: {self.test_results.passed}")
        print(f"{Fore.RED}   ‚ùå Fallidos: {self.test_results.failed}")
        print(f"{Fore.CYAN}   üìä Tasa de √©xito: {pass_rate:.1f}%")
        print(f"{Fore.CYAN}   ‚è±Ô∏è  Tiempo total: {self.test_results.total_duration:.2f}s")
        print(f"{Fore.CYAN}   üìä Tiempo promedio: {avg_duration:.3f}s")
        print(f"{Fore.CYAN}   üöÄ Score de rendimiento: {avg_performance:.1f}/100")

        # Clasificaci√≥n de calidad
        if pass_rate >= 95:
            quality = f"{Fore.GREEN}üåü EXCELENTE"
        elif pass_rate >= 85:
            quality = f"{Fore.YELLOW}‚úÖ BUENO"
        elif pass_rate >= 70:
            quality = f"{Fore.YELLOW}‚ö†Ô∏è  ACEPTABLE"
        else:
            quality = f"{Fore.RED}‚ùå NECESITA MEJORAS"

        print(f"\n{Fore.CYAN}üèÜ CALIDAD DEL CHATBOT: {quality}")

        # Tests fallidos
        failed_tests = [r for r in self.test_results.results if not r.passed]
        if failed_tests:
            print(f"\n{Fore.RED}‚ùå TESTS FALLIDOS:")
            for test in failed_tests[:10]:  # Mostrar m√°ximo 10
                print(f"{Fore.RED}   ‚Ä¢ {test.name}")
                if test.error:
                    print(f"{Fore.RED}     Error: {test.error[:100]}...")

        # Tests m√°s lentos
        slowest_tests = sorted(self.test_results.results, key=lambda x: x.duration, reverse=True)[:5]
        if slowest_tests:
            print(f"\n{Fore.YELLOW}üêå TESTS M√ÅS LENTOS:")
            for test in slowest_tests:
                print(f"{Fore.YELLOW}   ‚Ä¢ {test.name}: {test.duration:.3f}s")

        # Recomendaciones
        print(f"\n{Fore.CYAN}üí° RECOMENDACIONES:")
        if pass_rate < 90:
            print(f"{Fore.YELLOW}   ‚Ä¢ Revisar y corregir los tests fallidos")
        if avg_duration > 1.0:
            print(f"{Fore.YELLOW}   ‚Ä¢ Optimizar el rendimiento del chatbot")
        if avg_performance < 70:
            print(f"{Fore.YELLOW}   ‚Ä¢ Mejorar la velocidad de respuesta")

        print(f"{Fore.GREEN}   ‚Ä¢ El chatbot est√° funcionando correctamente" if pass_rate >= 90 else f"{Fore.RED}   ‚Ä¢ El chatbot necesita atenci√≥n")

        # Guardar reporte en JSON
        self._save_report_json()

        print(f"\n{Fore.CYAN}üíæ Reporte guardado en: reports/test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        print(f"{Fore.CYAN}{'=' * 80}\n")

    def _save_report_json(self):
        """Guarda el reporte en formato JSON"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Crear directorio de reportes si no existe
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)

        report_data = {
            "timestamp": timestamp,
            "difficulty": self.difficulty,
            "summary": {
                "total_tests": self.test_results.total_tests,
                "passed": self.test_results.passed,
                "failed": self.test_results.failed,
                "pass_rate": (self.test_results.passed / self.test_results.total_tests * 100) if self.test_results.total_tests > 0 else 0,
                "total_duration": self.test_results.total_duration,
                "avg_performance": sum(r.performance_score for r in self.test_results.results if r.performance_score) / len([r for r in self.test_results.results if r.performance_score]) if any(r.performance_score for r in self.test_results.results) else 0
            },
            "results": [
                {
                    "name": r.name,
                    "passed": r.passed,
                    "duration": r.duration,
                    "error": r.error,
                    "performance_score": r.performance_score
                }
                for r in self.test_results.results
            ]
        }

        report_file = reports_dir / f"test_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        # Limpiar reportes antiguos (mantener solo los √∫ltimos 10)
        self._cleanup_old_reports(reports_dir)

    def _cleanup_old_reports(self, reports_dir: Path):
        """Limpia reportes antiguos manteniendo solo los √∫ltimos 10"""
        try:
            import glob
            pattern = str(reports_dir / "test_report_*.json")
            reports = glob.glob(pattern)

            if len(reports) > 10:
                # Ordenar por fecha de modificaci√≥n y eliminar los m√°s antiguos
                reports.sort(key=lambda x: Path(x).stat().st_mtime)
                old_reports = reports[:-10]  # Mantener solo los √∫ltimos 10

                for old_report in old_reports:
                    try:
                        Path(old_report).unlink()
                    except Exception:
                        pass  # Ignorar errores al eliminar
        except Exception:
            pass  # Ignorar errores en la limpieza

    def run_all_tests(self):
        """Ejecuta toda la suite de tests"""
        self.print_header()

        try:
            # Tests b√°sicos
            self.test_basic_functionality()

            # Tests de dificultad media
            if self.difficulty in ["medium", "hard", "nightmare"]:
                self.test_medium_difficulty()

            # Tests extremos
            if self.difficulty in ["hard", "nightmare"]:
                self.test_extreme_cases()

            # Tests de rendimiento
            self.test_performance_stress()

            # Tests concurrentes
            if self.difficulty in ["medium", "hard", "nightmare"]:
                self.test_concurrent_access()

            # Tests de integraci√≥n
            self.test_document_integration()

            # Tests de funciones individuales
            self.test_functions_individually()

            # Generar reporte final
            self.generate_report()

        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}‚ö†Ô∏è  Tests interrumpidos por el usuario")
            self.generate_report()
        except Exception as e:
            print(f"\n{Fore.RED}‚ùå Error fatal en los tests: {e}")
            traceback.print_exc()


def show_menu():
    """Muestra el men√∫ interactivo"""
    print(f"\n{Fore.CYAN}üß™ SISTEMA DE TESTING UNIVERSAL - CHATBOT")
    print(f"{Fore.CYAN}{'=' * 50}")
    print(f"{Fore.YELLOW}Selecciona el nivel de dificultad:")
    print(f"{Fore.GREEN}1. üü¢ F√°cil      - Tests b√°sicos (10 iteraciones)")
    print(f"{Fore.YELLOW}2. üü° Medio     - Tests completos (50 iteraciones)")
    print(f"{Fore.RED}3. üî¥ Dif√≠cil    - Tests intensivos (100 iteraciones)")
    print(f"{Fore.MAGENTA}4. üíÄ Pesadilla - Tests extremos (500 iteraciones)")
    print(f"{Fore.BLUE}5. üìä Ver √∫ltimo reporte")
    print(f"{Fore.CYAN}6. ‚ùå Salir")
    print(f"{Fore.CYAN}{'=' * 50}")


def main():
    """Funci√≥n principal con men√∫ interactivo"""
    if len(sys.argv) > 1:
        # Modo comando directo
        difficulty = sys.argv[1] if sys.argv[1] in ["easy", "medium", "hard", "nightmare"] else "medium"
        suite = ChatbotTestSuite(difficulty=difficulty, verbose=True)
        suite.run_all_tests()
        return

    # Modo interactivo
    while True:
        show_menu()

        try:
            choice = input(f"\n{Fore.WHITE}Ingresa tu opci√≥n (1-6): ").strip()

            if choice == "1":
                suite = ChatbotTestSuite(difficulty="easy", verbose=True)
                suite.run_all_tests()
            elif choice == "2":
                suite = ChatbotTestSuite(difficulty="medium", verbose=True)
                suite.run_all_tests()
            elif choice == "3":
                suite = ChatbotTestSuite(difficulty="hard", verbose=True)
                suite.run_all_tests()
            elif choice == "4":
                confirm = input(f"{Fore.RED}‚ö†Ô∏è  Modo pesadilla puede tardar varios minutos. ¬øContinuar? (s/N): ")
                if confirm.lower() in ['s', 'si', 'y', 'yes']:
                    suite = ChatbotTestSuite(difficulty="nightmare", verbose=True)
                    suite.run_all_tests()
            elif choice == "5":
                # Buscar √∫ltimo reporte
                import glob
                reports = glob.glob("reports/test_report_*.json")
                if reports:
                    latest_report = max(reports)
                    with open(latest_report, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    print(f"\n{Fore.CYAN}üìä √öLTIMO REPORTE ({data['timestamp']}):")
                    print(f"{Fore.WHITE}Archivo: {latest_report}")
                    print(f"{Fore.WHITE}Dificultad: {data['difficulty']}")
                    print(f"{Fore.WHITE}Tests: {data['summary']['total_tests']}")
                    print(f"{Fore.GREEN}Pasados: {data['summary']['passed']}")
                    print(f"{Fore.RED}Fallidos: {data['summary']['failed']}")
                    print(f"{Fore.CYAN}Tasa de √©xito: {data['summary']['pass_rate']:.1f}%")
                else:
                    print(f"{Fore.YELLOW}No se encontraron reportes previos")
            elif choice == "6":
                print(f"{Fore.GREEN}¬°Hasta luego! üëã")
                break
            else:
                print(f"{Fore.RED}Opci√≥n inv√°lida. Por favor, selecciona 1-6.")

        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}Saliendo...")
            break
        except Exception as e:
            print(f"{Fore.RED}Error: {e}")


if __name__ == "__main__":
    main()
