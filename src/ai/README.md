# ğŸ¤– MÃ³dulo `ai/` - Inteligencia Artificial

## ğŸ“‹ DescripciÃ³n General

El mÃ³dulo `ai/` contiene todos los componentes relacionados con la Inteligencia Artificial del ChatBot de HotelerÃ­a. Este mÃ³dulo implementa un sistema completo de IA que incluye modelos de lenguaje, procesamiento de texto, bÃºsqueda semÃ¡ntica y gestiÃ³n de recursos.

## ğŸ—ï¸ Estructura del MÃ³dulo

```
ai/
â”œâ”€â”€ __init__.py              # ğŸ“¦ InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ models.py                # ğŸ§  GestiÃ³n de modelos de IA
â”œâ”€â”€ vectorstore.py           # ğŸ“š Base de conocimiento vectorial
â”œâ”€â”€ intent_detector.py       # ğŸ¯ DetecciÃ³n de intenciones
â”œâ”€â”€ text_generator.py        # âœï¸ GeneraciÃ³n de respuestas
â”œâ”€â”€ cache.py                 # ğŸ’¾ Sistema de cachÃ©
â”œâ”€â”€ resource_manager.py      # âš™ï¸ GestiÃ³n de recursos
â””â”€â”€ fallback_handler.py      # ğŸ›¡ï¸ Manejo de fallbacks
```

## ğŸ“„ DocumentaciÃ³n por Archivo

### ğŸ§  `models.py` - GestiÃ³n de Modelos de IA

**PropÃ³sito**: Centraliza la gestiÃ³n de todos los modelos de IA utilizados en el sistema.

**Estructura**:
- **ModelFactory**: Factory pattern para crear instancias de modelos
- **AIModels**: Clase principal que gestiona todos los modelos
- **Lazy Loading**: Sistema de carga perezosa para optimizar memoria

**Funcionalidades**:
- âœ… Carga de modelos de resumen (BERT2BERT)
- âœ… Carga de modelos de generaciÃ³n (GPT-2 Spanish)
- âœ… Carga de modelos de embeddings (Sentence Transformers)
- âœ… Carga de clasificadores de intenciones (BART)
- âœ… GestiÃ³n de recursos con carga perezosa
- âœ… Fallback a modelos dummy en caso de error

**Uso**:
```python
from ai.models import ai_models

# Obtener modelo de generaciÃ³n (async)
generator = await ai_models.get_generador()

# Obtener modelo de embeddings (async)
embeddings = await ai_models.get_embedding_model()

# Obtener estadÃ­sticas
stats = ai_models.get_stats()
```

**Dependencias**:
- `torch`: Framework de machine learning
- `transformers`: Modelos de Hugging Face
- `langchain_huggingface`: IntegraciÃ³n con LangChain
- `config.settings`: ConfiguraciÃ³n del sistema

---

### ğŸ“š `vectorstore.py` - Base de Conocimiento Vectorial

**PropÃ³sito**: Gestiona la base de conocimiento vectorial para bÃºsquedas semÃ¡nticas utilizando **base de datos SQLite** como fuente principal de documentos.

**Estructura**:
- **VectorStoreManager**: Clase principal para gestiÃ³n del vectorstore
- **IntegraciÃ³n con BD**: Uso directo de base de datos SQLite
- **BÃºsqueda SemÃ¡ntica**: BÃºsqueda por similitud vectorial con FAISS
- **GestiÃ³n de Chunks**: DivisiÃ³n inteligente de documentos desde BD

**Funcionalidades**:
- âœ… **Carga desde base de datos SQLite** (mÃ©todo principal)
- âœ… DivisiÃ³n automÃ¡tica en chunks optimizados
- âœ… BÃºsqueda semÃ¡ntica con FAISS
- âœ… ActualizaciÃ³n dinÃ¡mica de conocimiento desde BD
- âœ… GestiÃ³n de memoria con lazy loading
- âœ… EstadÃ­sticas de uso y rendimiento
- âœ… Fallback automÃ¡tico en caso de errores

**MÃ©todos Principales**:
```python
from ai.vectorstore import vectorstore_manager

# BÃºsqueda asÃ­ncrona (recomendado para lazy loading)
results = await vectorstore_manager.search_context_async("Â¿QuÃ© habitaciones tienen?", k=3)

# BÃºsqueda sÃ­ncrona (solo para modo inmediato)
results = vectorstore_manager.search_context("Â¿CuÃ¡l es el precio?", k=3)

# Actualizar conocimiento desde base de datos
vectorstore_manager.update_knowledge()

# Obtener estadÃ­sticas
stats = vectorstore_manager.get_stats()
```

**ConfiguraciÃ³n**:
- **Modo por Defecto**: Base de datos SQLite
- **Lazy Loading**: Activado para optimizar memoria
- **Chunk Size**: Configurable desde settings
- **Embedding Model**: Sentence Transformers

**Dependencias**:
- `faiss`: BÃºsqueda vectorial eficiente
- `langchain`: Framework para aplicaciones de IA
- `ai.models`: Modelos de embeddings

---

### ğŸ¯ `intent_detector.py` - DetecciÃ³n de Intenciones

**PropÃ³sito**: Clasifica automÃ¡ticamente las intenciones de los usuarios para proporcionar respuestas mÃ¡s precisas.

**Estructura**:
- **DetecciÃ³n de Intenciones**: ClasificaciÃ³n automÃ¡tica de consultas
- **Mapeo de Intenciones**: TraducciÃ³n de intenciones a acciones
- **Fallback Inteligente**: Manejo de casos no reconocidos

**Funcionalidades**:
- âœ… ClasificaciÃ³n automÃ¡tica de intenciones
- âœ… Soporte para mÃºltiples categorÃ­as (habitaciones, restaurantes, etc.)
- âœ… Fallback inteligente para casos no reconocidos
- âœ… IntegraciÃ³n con modelos de IA
- âœ… Cache de clasificaciones frecuentes

**Uso**:
```python
from ai.intent_detector import detect_intent

# Detectar intenciÃ³n
intent = detect_intent("Â¿QuÃ© habitaciones tienen disponibles?")
# Resultado: "habitaciones"

# Con contexto adicional
intent = detect_intent("Â¿CuÃ¡l es el precio de la suite?", context="precios")
# Resultado: "precios"
```

**Dependencias**:
- `ai.models`: Modelos de clasificaciÃ³n
- `ai.cache`: Sistema de cachÃ©

---

### âœï¸ `text_generator.py` - GeneraciÃ³n de Respuestas

**PropÃ³sito**: Genera respuestas contextuales y naturales basadas en la informaciÃ³n del hotel y las consultas de los usuarios.

**Estructura**:
- **GeneraciÃ³n Contextual**: Respuestas basadas en contexto relevante
- **Formateo de Respuestas**: AplicaciÃ³n de formato y estilo
- **ValidaciÃ³n de Calidad**: VerificaciÃ³n de respuestas generadas

**Funcionalidades**:
- âœ… GeneraciÃ³n de respuestas contextuales
- âœ… IntegraciÃ³n con base de conocimiento
- âœ… Formateo automÃ¡tico de respuestas
- âœ… ValidaciÃ³n de calidad de respuestas
- âœ… Soporte para mÃºltiples idiomas
- âœ… PersonalizaciÃ³n segÃºn tipo de consulta

**Uso**:
```python
from ai.text_generator import generate_response

# Generar respuesta simple
response = await generate_response("Â¿QuÃ© habitaciones tienen?")

# Generar respuesta con contexto especÃ­fico
response = await generate_response(
    "Â¿CuÃ¡l es el precio?", 
    context="habitaciones_precios.txt"
)
```

**Dependencias**:
- `ai.models`: Modelos de generaciÃ³n
- `ai.vectorstore`: Base de conocimiento
- `ai.intent_detector`: DetecciÃ³n de intenciones

---

### ğŸ’¾ `cache.py` - Sistema de CachÃ©

**PropÃ³sito**: Optimiza el rendimiento del sistema mediante el almacenamiento temporal de respuestas frecuentes.

**Estructura**:
- **Cache de Respuestas**: Almacenamiento de respuestas generadas
- **Cache de Modelos**: Cache de modelos cargados
- **GestiÃ³n de Memoria**: Control automÃ¡tico del tamaÃ±o del cache
- **PolÃ­ticas de EvicciÃ³n**: LRU para gestiÃ³n de memoria

**Funcionalidades**:
- âœ… Cache de respuestas con TTL configurable
- âœ… Cache de modelos para evitar recarga
- âœ… GestiÃ³n automÃ¡tica de memoria
- âœ… EstadÃ­sticas de rendimiento
- âœ… Limpieza automÃ¡tica de cache expirado
- âœ… PolÃ­tica LRU para evicciÃ³n

**Uso**:
```python
from ai.cache import response_cache

# Obtener respuesta del cache
response = response_cache.get("clave_consulta")

# Almacenar respuesta en cache
response_cache.set("clave_consulta", "respuesta", ttl=3600)

# Obtener estadÃ­sticas
stats = response_cache.get_stats()
```

**Dependencias**:
- `config.settings`: ConfiguraciÃ³n de cache
- `utils.logger`: Sistema de logging

---

### âš™ï¸ `resource_manager.py` - GestiÃ³n de Recursos

**PropÃ³sito**: Gestiona eficientemente los recursos del sistema, especialmente la memoria y la carga de modelos pesados.

**Estructura**:
- **GestiÃ³n de Memoria**: Control del uso de RAM
- **Carga Lazy**: Carga de modelos solo cuando es necesario
- **Control de Concurrencia**: GestiÃ³n de mÃºltiples requests simultÃ¡neos
- **Monitoreo de Recursos**: Seguimiento del uso de recursos

**Funcionalidades**:
- âœ… Carga perezosa de modelos pesados
- âœ… Control de concurrencia
- âœ… GestiÃ³n automÃ¡tica de memoria
- âœ… Monitoreo de recursos en tiempo real
- âœ… Limpieza automÃ¡tica de recursos no utilizados
- âœ… Fallback en caso de escasez de recursos

**Uso**:
```python
from ai.resource_manager import resource_manager

# Registrar modelo para carga perezosa
resource_manager.register_model("mi_modelo", create_function)

# Obtener modelo (se carga si es necesario)
model = await resource_manager.get_model("mi_modelo")

# Obtener estadÃ­sticas de recursos
stats = resource_manager.get_stats()
```

**Dependencias**:
- `config.settings`: ConfiguraciÃ³n de recursos
- `utils.logger`: Sistema de logging

---

### ğŸ›¡ï¸ `fallback_handler.py` - Manejo de Fallbacks

**PropÃ³sito**: Proporciona respuestas de respaldo utilizando **base de datos SQLite** como fuente principal de informaciÃ³n cuando los modelos de IA no estÃ¡n disponibles.

**Estructura**:
- **Proxy a Base de Datos**: RedirecciÃ³n directa a funciones de BD
- **Respuestas Contextuales**: Respuestas especÃ­ficas segÃºn tipo de consulta
- **Compatibilidad**: Funciones de compatibilidad para testing
- **GestiÃ³n de Errores**: Manejo robusto de errores

**Funcionalidades**:
- âœ… **IntegraciÃ³n completa con base de datos SQLite**
- âœ… Respuestas contextuales por tipo de consulta
- âœ… Funciones de compatibilidad para sistema de testing
- âœ… AnÃ¡lisis inteligente de consultas
- âœ… Fallback a respuestas por defecto
- âœ… Logging detallado de operaciones

**Funciones Principales**:
```python
from ai.fallback_handler import (
    generate_fallback_response,
    get_room_info_from_documents,
    get_restaurant_info_from_documents,
    get_amenities_info_from_documents,
    get_contact_info_from_documents,
    get_cheapest_room_info,
    get_most_expensive_room_info
)

# Generar respuesta de fallback automÃ¡tica
response = generate_fallback_response("Â¿QuÃ© habitaciones tienen?")

# Obtener informaciÃ³n especÃ­fica
room_info = get_room_info_from_documents()
restaurant_info = get_restaurant_info_from_documents()
cheapest_room = get_cheapest_room_info()
```

**IntegraciÃ³n**:
- **Fuente Principal**: Base de datos SQLite vÃ­a `database.fallback_main`
- **MÃ©todo de DetecciÃ³n**: AnÃ¡lisis de palabras clave en consultas
- **Fallback por Defecto**: Respuesta de bienvenida inteligente

**Dependencias**:
- `config.settings`: ConfiguraciÃ³n del sistema
- `utils.logger`: Sistema de logging

---

## ğŸ”§ CaracterÃ­sticas del MÃ³dulo

### âš¡ OptimizaciÃ³n de Rendimiento
- **Lazy Loading**: Carga de modelos solo cuando es necesario
- **Sistema de Cache**: Almacenamiento temporal de respuestas
- **GestiÃ³n de Memoria**: Control eficiente de recursos
- **BÃºsqueda Vectorial**: FAISS para bÃºsquedas rÃ¡pidas

### ğŸ”’ Robustez y Confiabilidad
- **Fallbacks Inteligentes**: Respuestas de respaldo automÃ¡ticas
- **Manejo de Errores**: GestiÃ³n centralizada de excepciones
- **ValidaciÃ³n**: VerificaciÃ³n de calidad de respuestas
- **RecuperaciÃ³n**: Mecanismos de recuperaciÃ³n automÃ¡tica

### ğŸ“ˆ Escalabilidad
- **Arquitectura Modular**: FÃ¡cil adiciÃ³n de nuevos modelos
- **ConfiguraciÃ³n Flexible**: Ajustes mediante variables de entorno
- **Monitoreo**: Seguimiento de rendimiento y recursos
- **Testing**: Pruebas automatizadas para cada componente

## ğŸš€ Inicio RÃ¡pido

```python
# Importar mÃ³dulo completo
from ai import *

# Usar modelos de IA
generator = await ai_models.get_generador()
response = await generate_response("Â¿QuÃ© servicios ofrecen?")

# Usar vectorstore
results = await vectorstore_manager.search_context_async("habitaciones")

# Usar cache
cached_response = response_cache.get("mi_consulta")
```

## ğŸ“ Notas de Desarrollo

- **Lazy Loading**: Habilitado por defecto para optimizar memoria
- **Cache**: Configurable mediante variables de entorno
- **Logging**: Todos los componentes usan el logger centralizado
- **Testing**: Cada componente tiene pruebas unitarias
- **DocumentaciÃ³n**: Mantener docstrings actualizados 