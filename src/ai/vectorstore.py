"""
Gesti√≥n de vectorstore y documentos
"""
import os
from typing import List

from config.settings import settings

# Importar adaptador de base de datos - REQUERIDO
from database.adapter import db_vectorstore_adapter
from utils.logger import logger

# Importaciones de langchain - condicionales para evitar errores
try:
    from langchain_community.document_loaders import (
        Docx2txtLoader,
        PyPDFLoader,
        TextLoader,
    )
    from langchain_community.vectorstores import FAISS
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    LANGCHAIN_AVAILABLE = True
    logger.info("‚úÖ Dependencias de LangChain cargadas correctamente")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Dependencias de LangChain no disponibles: {e}")
    logger.info("üí° Instala: pip install langchain langchain-community faiss-cpu")
    LANGCHAIN_AVAILABLE = False

from ai.models import ai_models

DATABASE_AVAILABLE = True
logger.info("üóÑÔ∏è Sistema configurado para usar base de datos SQLite")


class VectorStoreManager:
    """Gesti√≥n del vectorstore y documentos"""

    def __init__(self):
        self.vectorstore = None
        self._documents_processed = False
        self._chunks = []
        # Sistema configurado para usar SIEMPRE base de datos SQLite
        self.use_database = True

        # Inicializar text_splitter solo si langchain est√° disponible
        if LANGCHAIN_AVAILABLE:
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=settings.CHUNK_SIZE,
                chunk_overlap=settings.CHUNK_OVERLAP
            )
            logger.info("üóÑÔ∏è VectorStore inicializado - MODO BASE DE DATOS")
            logger.info("üîÑ VectorStore configurado en modo lazy loading")
        else:
            self.text_splitter = None
            logger.warning(
                "‚ö†Ô∏è VectorStore inicializado SIN dependencias de LangChain")
            logger.info(
                "üí° Funcionalidad limitada - instala las dependencias para funcionalidad completa")

    def _load_document(self, file_path: str) -> List:
        """Carga un documento seg√∫n su extensi√≥n"""
        extension = os.path.splitext(file_path)[1].lower()

        try:
            if extension == '.pdf':
                loader = PyPDFLoader(file_path)
            elif extension == '.txt':
                loader = TextLoader(file_path, encoding='utf-8')
            elif extension in ['.docx', '.doc']:
                loader = Docx2txtLoader(file_path)
            else:
                logger.warning(f"Formato no soportado: {extension}")
                return []

            documents = loader.load()
            logger.info(
                f"Documento cargado: {file_path} ({len(documents)} p√°ginas)")
            return documents

        except Exception as e:
            logger.error(f"Error al cargar {file_path}: {e}")
            return []

    def _prepare_documents(self):
        """Prepara los documentos desde la base de datos SQLite"""
        if self._documents_processed:
            return

        # SIEMPRE usar base de datos como fuente principal
        self._prepare_documents_from_database()

    def _prepare_documents_from_database(self):
        """Prepara documentos desde la base de datos SQLite"""
        try:
            logger.info(
                "üóÑÔ∏è Cargando documentos desde la base de datos SQLite...")
            documentos_db = db_vectorstore_adapter.get_all_documents_for_vectorstore()

            if not documentos_db:
                logger.warning(
                    "‚ö†Ô∏è No se encontraron documentos en la base de datos")
                logger.info(
                    "üí° Ejecuta: python migrate_to_database.py --migrate")
                return

            # Convertir a formato Document de langchain
            try:
                from langchain_core.documents import Document
            except ImportError:
                try:
                    from langchain.schema import Document
                except ImportError:
                    logger.error(
                        "‚ùå No se puede importar Document de langchain")
                    return

            all_docs = []

            for doc_data in documentos_db:
                doc = Document(
                    page_content=doc_data['page_content'],
                    metadata=doc_data['metadata']
                )
                all_docs.append(doc)

            logger.info(f"üìÑ Documentos de BD obtenidos: {len(all_docs)}")

            # Dividir documentos en chunks
            self._chunks = self.text_splitter.split_documents(all_docs)
            logger.info(
                f"üìÑ Documentos de BD divididos en {len(self._chunks)} chunks")
            self._documents_processed = True

        except Exception as e:
            logger.error(f"‚ùå Error al preparar documentos desde BD: {e}")
            logger.error(
                "ÔøΩ Aseg√∫rate de ejecutar la migraci√≥n: python migrate_to_database.py --migrate")
            # No hacer fallback a archivos - requerir base de datos
            raise RuntimeError(
                "Base de datos requerida pero no disponible. Ejecuta la migraci√≥n primero.")

    def _prepare_documents_from_files(self):
        """Prepara documentos desde archivos (m√©todo original)"""
        all_docs = []

        if not settings.DOCUMENTOS_DIR.exists():
            logger.warning(
                f"La carpeta {settings.DOCUMENTOS_DIR} no existe. Cre√°ndola...")
            settings.DOCUMENTOS_DIR.mkdir(parents=True, exist_ok=True)
            return

        # Procesar todos los archivos en la carpeta documentos
        for file_name in os.listdir(settings.DOCUMENTOS_DIR):
            file_path = settings.DOCUMENTOS_DIR / file_name
            if file_path.is_file():
                documents = self._load_document(str(file_path))
                if documents:
                    all_docs.extend(documents)

        if all_docs:
            # Dividir documentos en chunks (esto no requiere modelos pesados)
            self._chunks = self.text_splitter.split_documents(all_docs)
            logger.info(f"üìÑ Documentos divididos en {len(self._chunks)} chunks")
            self._documents_processed = True
        else:
            logger.warning("‚ö†Ô∏è No se encontraron documentos para procesar")

    def _create_vectorstore(self):
        """Crea el vectorstore SOLO cuando sea necesario (modo s√≠ncrono - solo para carga inmediata)"""
        if self.vectorstore is not None:
            return  # Ya est√° creado

        # Preparar documentos si no se ha hecho
        self._prepare_documents()

        if not self._chunks:
            logger.warning("‚ö†Ô∏è No hay chunks disponibles para crear vectorstore")
            return

        # Verificar si lazy loading est√° habilitado
        if ai_models.use_lazy_loading:
            logger.info("‚ö†Ô∏è Lazy loading habilitado - usa search_context_async() para crear vectorstore")
            return

        # Aqu√≠ es donde se cargan los modelos pesados (solo modo inmediato)
        logger.info("‚è≥ Cargando modelo de embeddings (puede tardar un momento)...")
        try:
            embedding_model = ai_models.get_embedding_model_sync()
            if embedding_model:
                self.vectorstore = FAISS.from_documents(
                    self._chunks, embedding_model)
                logger.info("‚úÖ Vectorstore creado exitosamente")
            else:
                logger.warning("‚ö†Ô∏è Modelo de embeddings no disponible")
        except Exception as e:
            logger.error(f"‚ùå Error creando vectorstore: {e}")

    def search_context(self, question: str, k: int = 3) -> List[str]:
        """Busca contexto relevante para una pregunta"""
        # Verificar si lazy loading est√° habilitado
        if ai_models.use_lazy_loading:
            logger.warning("‚ö†Ô∏è Lazy loading habilitado - usa search_context_async() en su lugar")
            return []

        # Si no existe el vectorstore, crearlo ahora (solo modo inmediato)
        if not self.vectorstore:
            logger.info(
                "üîÑ Vectorstore no disponible, inicializando desde base de datos...")
            self._create_vectorstore()

        if not self.vectorstore:
            logger.warning("‚ùå Vectorstore no disponible despu√©s de intentar crearlo")
            return []

        try:
            docs = self.vectorstore.similarity_search(question, k=k)
            logger.info(
                f"‚úÖ Encontrados {len(docs)} documentos relevantes desde BD")
            return [doc.page_content for doc in docs]
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de contexto: {e}")
            return []

    async def search_context_async(self, question: str, k: int = 3) -> List[str]:
        """Busca contexto relevante para una pregunta (m√©todo as√≠ncrono para lazy loading)"""
        if not self.vectorstore:
            # Intentar crear el vectorstore con lazy loading
            await self._create_vectorstore_async()

            if not self.vectorstore:
                logger.warning(
                    "‚ùå Vectorstore no disponible despu√©s de intentar crearlo")
                return []

        try:
            docs = self.vectorstore.similarity_search(question, k=k)
            logger.info(f"‚úÖ Encontrados {len(docs)} documentos relevantes (async)")
            return [doc.page_content for doc in docs]
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de contexto (async): {e}")
            return []

    async def _create_vectorstore_async(self):
        """Crea el vectorstore de forma as√≠ncrona (para lazy loading)"""
        if self.vectorstore is not None:
            return  # Ya est√° creado

        # Preparar documentos si no se ha hecho
        self._prepare_documents()

        if not self._chunks:
            logger.warning("‚ö†Ô∏è No hay chunks disponibles para crear vectorstore")
            return

        logger.info("‚è≥ Cargando modelo de embeddings de forma as√≠ncrona...")
        try:
            embedding_model = await ai_models.get_embedding_model()
            if embedding_model:
                self.vectorstore = FAISS.from_documents(
                    self._chunks, embedding_model)
                logger.info("‚úÖ Vectorstore creado exitosamente (async)")
            else:
                logger.warning("‚ö†Ô∏è Modelo de embeddings no disponible")
        except Exception as e:
            logger.error(f"‚ùå Error al crear vectorstore async: {e}")

    def update_knowledge(self):
        """Actualiza el conocimiento del vectorstore (sin cargar modelos pesados)"""
        logger.info("üìö Actualizando conocimiento...")
        # Solo preparar documentos, no cargar modelos hasta que sea necesario
        self._prepare_documents()
        # Limpiar vectorstore existente para forzar recreaci√≥n en pr√≥xima b√∫squeda
        self.vectorstore = None
        logger.info("‚úÖ Conocimiento actualizado (lazy loading activado)")

    def reload_document(self, file_path: str):
        """Recarga un documento espec√≠fico en el vectorstore"""
        try:
            logger.info(f"üîÑ Recargando documento: {file_path}")

            # Para simplicidad, reconstruir todo el vectorstore
            # En una implementaci√≥n m√°s avanzada, se podr√≠a actualizar solo el documento espec√≠fico
            self._create_vectorstore()

            logger.info(f"‚úÖ Documento recargado: {file_path}")

        except Exception as e:
            logger.error(f"‚ùå Error al recargar documento {file_path}: {e}")

    def add_document(self, file_path: str):
        """A√±ade un nuevo documento al vectorstore"""
        try:
            logger.info(f"‚ûï A√±adiendo documento: {file_path}")

            documents = self._load_document(file_path)
            if not documents:
                logger.warning(f"No se pudo cargar el documento: {file_path}")
                return

            # Dividir en chunks
            chunks = self.text_splitter.split_documents(documents)

            if self.vectorstore:
                # A√±adir al vectorstore existente
                embedding_model = ai_models.get_embedding_model_sync()
                if embedding_model:
                    self.vectorstore.add_documents(chunks)
                    logger.info(
                        f"‚úÖ Documento a√±adido: {file_path} ({len(chunks)} chunks)")
                else:
                    logger.error("Modelo de embeddings no disponible")
            else:
                # Crear nuevo vectorstore si no existe
                self._create_vectorstore()

        except Exception as e:
            logger.error(f"‚ùå Error al a√±adir documento {file_path}: {e}")

    def remove_document(self, file_path: str):
        """Elimina un documento del vectorstore"""
        try:
            logger.info(f"üóëÔ∏è Eliminando documento: {file_path}")

            # Para simplicidad, reconstruir todo el vectorstore sin el documento eliminado
            # En una implementaci√≥n m√°s avanzada, se podr√≠a eliminar solo el documento espec√≠fico
            self._create_vectorstore()

            logger.info(f"‚úÖ Documento eliminado: {file_path}")

        except Exception as e:
            logger.error(f"‚ùå Error al eliminar documento {file_path}: {e}")

    def get_document_count(self) -> int:
        """Retorna el n√∫mero de documentos en el vectorstore"""
        if not self.vectorstore:
            return 0
        return len(self.vectorstore.docstore._dict)

    def get_stats(self) -> dict:
        """Retorna estad√≠sticas del vectorstore"""
        if not self.vectorstore:
            return {
                'document_count': 0,
                'vectorstore_created': False,
                'embedding_model': 'N/A'
            }

        return {
            'document_count': self.get_document_count(),
            'vectorstore_created': True,
            'embedding_model': settings.MODELO_EMBEDDINGS
        }


# Instancia global del vectorstore
vectorstore_manager = VectorStoreManager()
